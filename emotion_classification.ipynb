{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emotion classification with BERT\n",
    "\n",
    "This notebook focuses on classifying text with emotions using the BERT transformer model. The goal is to analyze and understand the emotions conveyed in textual data.\n",
    "\n",
    "By Constant Fotie Moghommahie\n",
    "\n",
    "[fotiecodes](https://fotiecodes.com).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classes: \n",
    "```json {\n",
    "    'sadness': 0,\n",
    "    'fear': 1,\n",
    "    'anger': 2,\n",
    "    'love': 3,\n",
    "    'happy': 4,\n",
    "    'surprise': 5\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import and install neccessary libs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /Users/fotiem.constant/anaconda3/envs/ml-env/lib/python3.10/site-packages (3.8.1)\n",
      "Requirement already satisfied: click in /Users/fotiem.constant/anaconda3/envs/ml-env/lib/python3.10/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /Users/fotiem.constant/anaconda3/envs/ml-env/lib/python3.10/site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/fotiem.constant/anaconda3/envs/ml-env/lib/python3.10/site-packages (from nltk) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in /Users/fotiem.constant/anaconda3/envs/ml-env/lib/python3.10/site-packages (from nltk) (4.66.1)\n",
      "Requirement already satisfied: tensorflow in /Users/fotiem.constant/anaconda3/envs/ml-env/lib/python3.10/site-packages (2.15.0)\n",
      "Requirement already satisfied: tensorflow-macos==2.15.0 in /Users/fotiem.constant/anaconda3/envs/ml-env/lib/python3.10/site-packages (from tensorflow) (2.15.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/fotiem.constant/anaconda3/envs/ml-env/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/fotiem.constant/anaconda3/envs/ml-env/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /Users/fotiem.constant/anaconda3/envs/ml-env/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Users/fotiem.constant/anaconda3/envs/ml-env/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/fotiem.constant/anaconda3/envs/ml-env/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Users/fotiem.constant/anaconda3/envs/ml-env/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow) (3.10.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/fotiem.constant/anaconda3/envs/ml-env/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in /Users/fotiem.constant/anaconda3/envs/ml-env/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /Users/fotiem.constant/anaconda3/envs/ml-env/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow) (1.26.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/fotiem.constant/anaconda3/envs/ml-env/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /Users/fotiem.constant/anaconda3/envs/ml-env/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Users/fotiem.constant/anaconda3/envs/ml-env/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow) (4.23.4)\n",
      "Requirement already satisfied: setuptools in /Users/fotiem.constant/anaconda3/envs/ml-env/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/fotiem.constant/anaconda3/envs/ml-env/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/fotiem.constant/anaconda3/envs/ml-env/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/fotiem.constant/anaconda3/envs/ml-env/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow) (4.9.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /Users/fotiem.constant/anaconda3/envs/ml-env/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/fotiem.constant/anaconda3/envs/ml-env/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow) (0.34.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/fotiem.constant/anaconda3/envs/ml-env/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow) (1.48.2)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in /Users/fotiem.constant/anaconda3/envs/ml-env/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /Users/fotiem.constant/anaconda3/envs/ml-env/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in /Users/fotiem.constant/anaconda3/envs/ml-env/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/fotiem.constant/anaconda3/envs/ml-env/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow-macos==2.15.0->tensorflow) (0.41.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/fotiem.constant/anaconda3/envs/ml-env/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (2.25.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /Users/fotiem.constant/anaconda3/envs/ml-env/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (1.2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/fotiem.constant/anaconda3/envs/ml-env/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (3.5.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/fotiem.constant/anaconda3/envs/ml-env/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/fotiem.constant/anaconda3/envs/ml-env/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/fotiem.constant/anaconda3/envs/ml-env/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/fotiem.constant/anaconda3/envs/ml-env/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/fotiem.constant/anaconda3/envs/ml-env/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/fotiem.constant/anaconda3/envs/ml-env/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/fotiem.constant/anaconda3/envs/ml-env/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/fotiem.constant/anaconda3/envs/ml-env/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/fotiem.constant/anaconda3/envs/ml-env/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/fotiem.constant/anaconda3/envs/ml-env/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/fotiem.constant/anaconda3/envs/ml-env/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (2023.11.17)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/fotiem.constant/anaconda3/envs/ml-env/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /Users/fotiem.constant/anaconda3/envs/ml-env/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (0.5.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/fotiem.constant/anaconda3/envs/ml-env/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install nltk\n",
    "!pip3 install --upgrade tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#import tensorflow_hub as hub\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import re\n",
    "import unicodedata\n",
    "from nltk.corpus import stopwords\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense,Dropout, Input\n",
    "#from tqdm import tqdm\n",
    "import pickle\n",
    "from sklearn.metrics import confusion_matrix,f1_score,classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/fotiem.constant/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fotiem.constant/anaconda3/envs/ml-env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, TFBertModel, BertConfig,TFDistilBertModel,DistilBertTokenizer,DistilBertConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.  Preprocessing and cleaning functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unicode_to_ascii(s):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "def clean_stopwords_shortwords(w):\n",
    "    stopwords_list=stopwords.words('english')\n",
    "    words = w.split() \n",
    "    clean_words = [word for word in words if (word not in stopwords_list) and len(word) > 2]\n",
    "    return \" \".join(clean_words) \n",
    "\n",
    "def preprocess_sentence(w):\n",
    "    w = unicode_to_ascii(w.lower().strip())\n",
    "    w = re.sub(r\"([?.!,¿])\", r\" \", w)\n",
    "    w = re.sub(r'[\" \"]+', \" \", w)\n",
    "    w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
    "    w=clean_stopwords_shortwords(w)\n",
    "    w=re.sub(r'@\\w+', '',w)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Load and Inspect our dataset\n",
    "We will first load and and preview our dataset. So we can check for any missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Emotion\n",
       "0                            i didnt feel humiliated  sadness\n",
       "1  i can go from feeling so hopeless to so damned...  sadness\n",
       "2   im grabbing a minute to post i feel greedy wrong    anger\n",
       "3  i am ever feeling nostalgic about the fireplac...     love\n",
       "4                               i am feeling grouchy    anger"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load and inspect the new dataset\n",
    "data_file = './data/emotion_final.csv'\n",
    "\n",
    "# Read the data from the CSV file into a pandas DataFrame\n",
    "data=pd.read_csv(data_file,encoding='ISO-8859-1')\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">  Removing Unnamed Columns, dropping NaN data and resetting the index after dropping some rows/columns containing NaN dataset and finally shuffling the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File has 21459 rows and 2 columns\n",
      "File has 21459 rows and 2 columns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2168</th>\n",
       "      <td>i couldnt bring myself to blog about it right ...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3814</th>\n",
       "      <td>i have eternal hope he says and when they arri...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7834</th>\n",
       "      <td>i have a feeling that it is in canada where sh...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1611</th>\n",
       "      <td>i remember that beauty truly is in the eye of ...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>i recall those high school feelings and the lo...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text  Emotion\n",
       "2168  i couldnt bring myself to blog about it right ...  sadness\n",
       "3814  i have eternal hope he says and when they arri...     love\n",
       "7834  i have a feeling that it is in canada where sh...    happy\n",
       "1611  i remember that beauty truly is in the eye of ...     fear\n",
       "336   i recall those high school feelings and the lo...     love"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('File has {} rows and {} columns'.format(data.shape[0],data.shape[1]))\n",
    "data=data.dropna()\n",
    "data=data.reset_index(drop=True)\n",
    "print('File has {} rows and {} columns'.format(data.shape[0],data.shape[1]))\n",
    "data = shuffle(data)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>gt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2168</th>\n",
       "      <td>couldnt bring blog right away mostly feel abso...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3814</th>\n",
       "      <td>eternal hope says arrive bridge finds likes fe...</td>\n",
       "      <td>love</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7834</th>\n",
       "      <td>feeling canada find prince charming</td>\n",
       "      <td>happy</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1611</th>\n",
       "      <td>remember beauty truly eye beholder people see ...</td>\n",
       "      <td>fear</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>recall high school feelings longing watched ol...</td>\n",
       "      <td>love</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text    label  gt\n",
       "2168  couldnt bring blog right away mostly feel abso...  sadness   0\n",
       "3814  eternal hope says arrive bridge finds likes fe...     love   1\n",
       "7834                feeling canada find prince charming    happy   2\n",
       "1611  remember beauty truly eye beholder people see ...     fear   3\n",
       "336   recall high school feelings longing watched ol...     love   1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=data.rename(columns = {'Emotion': 'label', 'Text': 'text'}, inplace = False)\n",
    "\n",
    "# Ensure all unique labels are included in the mapping dictionary\n",
    "unique_labels = data['label'].unique()\n",
    "mapping_dict = {label: index for index, label in enumerate(unique_labels)}\n",
    "\n",
    "data['gt'] = data['label'].map(mapping_dict)\n",
    "\n",
    "# Fill NaN values with a specific value (e.g., -1) and convert to integer\n",
    "data['gt'] = data['gt'].fillna(-1).astype(int)\n",
    "\n",
    "data['text']=data['text'].map(preprocess_sentence)\n",
    "\n",
    "num_classes=len(data.label.unique())\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  4. Loading DistilBERT Tokenizer and the DistilBERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbert_tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertModel: ['vocab_transform.weight', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing TFDistilBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFDistilBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "dbert_model = TFDistilBertModel.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  5. Preparing input for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21459, 21459)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the maximum length of the input sentences\n",
    "max_len = 32\n",
    "\n",
    "# Get the sentences and labels from the data\n",
    "sentences = data['text']\n",
    "labels = data['gt']\n",
    "\n",
    "# Print the length of the sentences and labels\n",
    "len(sentences), len(labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Let's take a sentence from the dataset and understand the input and output of the DistilBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'didnt feel humiliated'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['didn', '##t', 'feel', 'humiliated']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbert_tokenizer.tokenize(sentences[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Input ids and the attention masks from the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fotiem.constant/anaconda3/envs/ml-env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2618: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 2134, 2102, 2514, 26608, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbert_inp=dbert_tokenizer.encode_plus(sentences[0],add_special_tokens = True,max_length =20,pad_to_max_length = True,truncation=True)\n",
    "dbert_inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 2134, 2102, 2514, 26608, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbert_inp['input_ids']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">  DistilBERT model output: Give input_ids and the attention_mask obtained from the tokenizer. The output will be a tuple of the size (1,max_len,768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(transformers.modeling_tf_outputs.TFBaseModelOutput,\n",
       " TFBaseModelOutput(last_hidden_state=<tf.Tensor: shape=(1, 20, 768), dtype=float32, numpy=\n",
       " array([[[-0.1713852 ,  0.04808453, -0.11152899, ..., -0.06434262,\n",
       "           0.3309234 ,  0.36421138],\n",
       "         [ 0.35398236,  0.237599  ,  0.21699837, ...,  0.00849791,\n",
       "           0.46305755, -0.41722137],\n",
       "         [-0.41779673,  0.0801597 ,  0.4836889 , ..., -0.17692386,\n",
       "           0.5626378 ,  0.43658376],\n",
       "         ...,\n",
       "         [-0.15297808,  0.03547417,  0.06371693, ...,  0.03469767,\n",
       "           0.0273383 , -0.1618905 ],\n",
       "         [-0.14419594,  0.06348429,  0.07919774, ...,  0.11205912,\n",
       "           0.0483825 , -0.20951898],\n",
       "         [-0.11421237,  0.06052669,  0.07216734, ...,  0.1228725 ,\n",
       "           0.0578859 , -0.19464041]]], dtype=float32)>, hidden_states=None, attentions=None))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_inp=np.asarray(dbert_inp['input_ids'])\n",
    "mask_inp=np.asarray(dbert_inp['attention_mask'])\n",
    "out=dbert_model([id_inp.reshape(1,-1),mask_inp.reshape(1,-1)])\n",
    "type(out),out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Obtain the embeddings of a sentence from the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 768), dtype=float32, numpy=\n",
       "array([[-1.71385199e-01,  4.80845273e-02, -1.11528993e-01,\n",
       "        -2.09115595e-02, -2.34398291e-01, -4.43111286e-02,\n",
       "         2.90086627e-01,  2.66656905e-01,  2.05921069e-01,\n",
       "        -2.20593572e-01,  5.82962371e-02, -2.02092111e-01,\n",
       "        -1.94992542e-01,  1.50783718e-01,  9.85640213e-02,\n",
       "         5.78697622e-02,  2.98279021e-02,  1.51283830e-01,\n",
       "         6.53628679e-03, -5.72892092e-02, -7.78306574e-02,\n",
       "        -3.38846177e-01, -1.36250377e-01,  7.62554258e-02,\n",
       "        -1.06427208e-01,  3.59946080e-02,  1.48689047e-01,\n",
       "        -3.07668447e-01,  6.57811016e-02, -1.10575236e-01,\n",
       "         6.58358634e-02,  2.32130304e-01, -1.61469772e-01,\n",
       "         2.03121938e-02, -1.84822798e-01,  1.77119240e-01,\n",
       "         3.92265581e-02,  1.18414432e-01,  1.43307313e-01,\n",
       "         1.92273743e-02, -2.72444546e-01, -5.23973629e-02,\n",
       "        -2.44558126e-01, -4.83159423e-02,  1.09537050e-01,\n",
       "        -1.48615092e-01, -2.21261787e+00, -3.53776738e-02,\n",
       "        -3.09246689e-01, -5.51776737e-02,  3.77840072e-01,\n",
       "        -1.60715342e-01,  1.36903584e-01,  2.55552649e-01,\n",
       "        -3.15836444e-02,  3.86984706e-01, -2.13476360e-01,\n",
       "         2.70367116e-01,  2.19966508e-02,  1.20392427e-01,\n",
       "         1.89636216e-01,  2.10117564e-01, -2.26430133e-01,\n",
       "         4.09135334e-02, -5.76002635e-02,  2.83537507e-01,\n",
       "        -1.17895357e-01,  4.58773732e-01, -2.02765808e-01,\n",
       "         2.75058240e-01, -2.53737777e-01, -2.13359773e-01,\n",
       "         2.41958320e-01,  3.00891213e-02,  2.36203700e-01,\n",
       "        -1.02853343e-01,  1.36533566e-02, -7.87596256e-02,\n",
       "        -1.16305053e-01,  2.83179104e-01,  4.35256436e-02,\n",
       "         3.33482981e-01,  1.19095869e-01,  2.50336826e-01,\n",
       "         6.08267039e-02,  1.56001806e-01, -1.33856267e-01,\n",
       "        -1.35660112e-01,  2.31804579e-01,  2.31329143e-01,\n",
       "        -6.94522411e-02, -1.00743517e-01,  1.64541110e-01,\n",
       "         1.07205234e-01,  1.72117800e-01, -2.30545282e-01,\n",
       "         6.52416795e-02, -6.39436841e-02,  4.12916273e-01,\n",
       "         1.95157945e-01,  7.50757232e-02, -1.60083026e-01,\n",
       "        -1.20999627e-02, -3.00561816e-01, -1.73729181e-01,\n",
       "        -6.42000139e-02, -1.13450080e-01, -3.18936020e-01,\n",
       "         1.10169370e-02, -2.48620749e+00,  2.39081576e-01,\n",
       "         1.17219627e-01, -1.13289446e-01, -4.75271761e-01,\n",
       "        -7.78912157e-02,  4.97977108e-01,  3.31521153e-01,\n",
       "        -7.51513988e-02, -1.25041649e-01, -4.47302535e-02,\n",
       "         5.14972433e-02,  1.76549762e-01,  1.51390508e-01,\n",
       "        -8.48708153e-02, -5.30066565e-02,  1.39039785e-01,\n",
       "         5.40549234e-02, -1.87353700e-01,  5.42768873e-02,\n",
       "         2.23130181e-01,  2.74579138e-01,  4.20294017e-01,\n",
       "        -4.53179628e-02,  1.08983487e-01, -3.78529310e-01,\n",
       "         6.30204976e-02,  1.46910354e-01, -8.19532797e-02,\n",
       "        -8.61303657e-02, -2.16236323e-01, -2.02109396e-01,\n",
       "         3.14533263e-02, -2.81477666e+00,  3.04785430e-01,\n",
       "         4.89276886e-01, -1.44146383e-04,  1.53730348e-01,\n",
       "         6.45868629e-02, -2.91426014e-02,  1.34964570e-01,\n",
       "         1.05309248e-01,  1.89804912e-01, -1.63517877e-01,\n",
       "        -1.12992786e-02, -2.39062414e-01,  1.60337210e-01,\n",
       "        -2.04973742e-01,  1.13692537e-01,  4.03580487e-01,\n",
       "         2.52418041e-01,  1.91251785e-02, -1.53147861e-01,\n",
       "        -9.98563319e-02, -3.09814438e-02,  6.90934360e-02,\n",
       "         6.85143918e-02,  5.48528880e-02,  1.76367074e-01,\n",
       "         2.42069513e-01, -1.32107228e-01,  1.28133297e-01,\n",
       "        -1.20570041e-01,  3.40107143e-01, -1.00989640e-01,\n",
       "         1.06453717e-01, -1.59793034e-01,  2.98378468e-01,\n",
       "         2.19959453e-01, -1.42658502e-01,  4.52701822e-02,\n",
       "        -2.40304023e-01,  2.96431094e-01,  6.20561242e-02,\n",
       "         4.34365757e-02,  1.01894438e-01,  1.38625354e-01,\n",
       "         2.96794444e-01, -3.64211917e-01, -9.96032804e-02,\n",
       "         2.87841946e-01, -3.66397917e-01, -2.27272689e-01,\n",
       "        -1.92059174e-01,  7.08746463e-02,  3.77416909e-01,\n",
       "        -2.24604174e-01, -3.78494114e-02, -2.90221512e-01,\n",
       "         1.93442032e-01,  5.13497479e-02, -1.84562236e-01,\n",
       "        -3.44922364e-01, -5.88606894e-02,  2.38372996e-01,\n",
       "         5.29491901e-03,  3.55634236e+00, -8.14667642e-02,\n",
       "        -2.42045358e-01,  1.77641988e-01,  3.14603925e-01,\n",
       "        -4.86686788e-02, -6.46347851e-02, -6.48585856e-02,\n",
       "        -8.25555343e-03,  2.61280723e-02, -8.71600434e-02,\n",
       "         2.52242029e-01, -1.81538254e-01, -3.18679772e-02,\n",
       "        -4.62348713e-03,  2.31858879e-01, -8.62366781e-02,\n",
       "        -4.75831442e-02,  6.43650070e-03, -1.39836833e-01,\n",
       "         2.20672965e-01,  1.25310540e-01,  1.48932770e-01,\n",
       "        -5.90122119e-02, -1.38019979e+00, -1.29714042e-01,\n",
       "        -1.50800392e-01,  4.09856811e-02,  3.03183198e-01,\n",
       "        -2.41809458e-01, -5.37861846e-02,  1.73012763e-01,\n",
       "        -1.19087566e-03,  2.15842463e-02,  1.07249290e-01,\n",
       "        -2.44865790e-01,  1.98535472e-01,  4.09471512e-01,\n",
       "         2.19657272e-01, -3.52734476e-01,  3.82150739e-01,\n",
       "         4.44891393e-01, -2.69480068e-02,  9.17763859e-02,\n",
       "        -5.72812185e-02,  3.19885612e-01, -9.80711132e-02,\n",
       "        -1.03323214e-01, -1.66089743e-01,  1.78676695e-02,\n",
       "        -1.55722037e-01,  1.63337797e-01, -4.86563072e-02,\n",
       "        -2.63091594e-01, -2.52352178e-01, -9.61506441e-02,\n",
       "         1.46084905e-01,  3.63961339e-01,  2.40882933e-01,\n",
       "        -2.16162652e-01, -1.83926657e-01,  1.20740518e-01,\n",
       "        -2.18235031e-01,  2.73817658e-01,  8.92959386e-02,\n",
       "        -1.58058256e-02, -9.44467187e-02, -2.49685854e-01,\n",
       "        -3.59410787e+00, -1.51947320e-01,  1.03521034e-01,\n",
       "         3.58737051e-01,  3.87252867e-01, -1.71165913e-01,\n",
       "        -4.28580344e-02,  6.93487450e-02,  4.07407075e-01,\n",
       "        -5.23736477e-01,  3.78721267e-01,  2.74168432e-01,\n",
       "         9.66793448e-02,  1.14795953e-01, -3.94072115e-01,\n",
       "         2.91700631e-01, -1.59666881e-01, -3.21382470e-02,\n",
       "         3.88058871e-02,  1.40456706e-01, -2.51046736e-02,\n",
       "         3.09824288e-01, -7.11079128e-03,  4.54306230e-02,\n",
       "        -2.57164985e-03,  1.63144901e-01,  1.16625667e-01,\n",
       "        -2.95956165e-01,  1.01467781e-02, -7.55885690e-02,\n",
       "         5.97735345e-02, -2.56760299e-01,  1.20577440e-01,\n",
       "        -5.60367852e-02, -1.59051657e-01, -2.65954137e+00,\n",
       "        -2.29781702e-01,  1.45233229e-01, -1.83815554e-01,\n",
       "         1.92415491e-01, -1.16836354e-01,  2.17755884e-01,\n",
       "        -1.73737302e-01, -3.16536903e-01,  1.93931818e-01,\n",
       "         2.58156657e-01, -3.10992837e-01,  1.93742752e-01,\n",
       "         2.32987881e-01,  4.71677452e-01, -1.01608112e-02,\n",
       "         3.46235067e-01, -4.30719614e-01,  2.54952163e-03,\n",
       "         1.82718575e-01, -1.05712283e-03, -6.88093752e-02,\n",
       "        -5.39683886e-02, -2.02291295e-01,  1.49459377e-01,\n",
       "         5.08890510e-01, -3.04890811e-01,  6.92824721e-02,\n",
       "        -2.15019092e-01, -3.91290486e-02, -2.74561159e-02,\n",
       "        -1.54505581e-01,  5.77242561e-02,  1.33657828e-01,\n",
       "        -4.13259901e-02, -2.73489952e-01,  1.52300060e-01,\n",
       "         1.30426079e-01,  2.09828496e-01,  1.28479246e-02,\n",
       "        -5.71452379e-02,  3.03664804e-01, -8.40190426e-03,\n",
       "         1.83006033e-01,  3.68612647e-01,  7.40124583e-02,\n",
       "        -1.05772436e-01, -2.69602805e-01, -1.17974207e-01,\n",
       "         1.98808178e-01, -2.49161329e-02,  1.38784811e-01,\n",
       "         1.13749611e+00, -5.86785637e-02,  2.78955489e-01,\n",
       "        -1.70916528e-01,  9.82148200e-02,  1.83147982e-01,\n",
       "        -6.10212348e-02, -3.21694426e-02,  1.98484585e-01,\n",
       "         1.77195854e-02,  2.12274157e-02, -1.02970693e-02,\n",
       "        -3.81245092e-02, -1.61226183e-01,  4.82719205e-02,\n",
       "        -2.66769499e-01,  1.20722950e-02,  3.27195257e-01,\n",
       "        -1.95990596e-02,  1.44174203e-01,  1.87642761e-02,\n",
       "        -8.77612412e-01, -2.92940736e-01,  3.56066614e-01,\n",
       "        -1.42777920e-01, -1.39469311e-01, -7.02299997e-02,\n",
       "        -3.56428213e-02, -3.60453367e-01,  4.51997016e-03,\n",
       "        -1.49295986e-01,  1.12126209e-01, -2.02312768e-01,\n",
       "         9.66560096e-03, -3.91341895e-02,  5.31728044e-02,\n",
       "        -3.76352549e-01, -1.09153256e-01,  7.60204196e-02,\n",
       "         2.76892811e-01,  1.93607599e-01,  2.53630817e-01,\n",
       "         8.06428492e-02, -5.21412641e-02,  3.21765572e-01,\n",
       "        -6.31081104e-01,  6.22723810e-02, -2.56033152e-01,\n",
       "        -5.66748530e-02, -3.12875807e-01, -2.14644298e-01,\n",
       "         1.04578033e-01, -2.64345139e-01, -1.48783058e-01,\n",
       "        -4.35317844e-01,  3.67390454e-01, -5.81242181e-02,\n",
       "         2.19410762e-01, -6.16728738e-02,  8.76492560e-02,\n",
       "        -3.52051519e-02,  2.96966314e-01,  9.28597748e-01,\n",
       "        -2.29679614e-01,  8.33450034e-02,  3.37287098e-01,\n",
       "         2.19596922e-02,  4.22581941e-01,  3.17786932e-01,\n",
       "         2.10245475e-01, -2.38253981e-01, -9.85659808e-02,\n",
       "        -1.88133687e-01,  1.28842741e-01, -3.00583038e-02,\n",
       "        -3.93236637e-01, -3.66457880e-01, -1.99069530e-01,\n",
       "         4.11940157e-01,  7.27880150e-02, -2.62691259e-01,\n",
       "        -5.77453494e-01,  1.00616947e-01, -3.60695362e-01,\n",
       "        -1.52788088e-02,  8.65646303e-02,  5.47446720e-02,\n",
       "         1.14691697e-01,  3.25779468e-01,  2.60380395e-02,\n",
       "        -2.19637394e-01,  2.81935871e-01, -9.00078937e-02,\n",
       "         4.51918662e-01, -8.02451372e-03, -2.32060209e-01,\n",
       "        -3.45115699e-02,  5.30513346e-01, -9.02971029e-02,\n",
       "        -3.10162604e-01,  1.36168167e-01, -1.40956923e-01,\n",
       "         2.43669242e-01,  8.92598480e-02, -3.08476686e-02,\n",
       "        -1.10532433e-01, -1.34519607e-01, -1.61218315e-01,\n",
       "        -1.10282227e-02,  1.34611309e-01, -1.33931887e+00,\n",
       "         4.22265321e-01,  3.25056076e-01, -2.78467119e-01,\n",
       "         2.63327390e-01, -1.69587895e-01, -3.21623445e-01,\n",
       "         3.13937783e-01,  2.21853107e-01,  6.70546666e-03,\n",
       "         3.84418927e-02,  1.77364480e-02, -1.75623670e-01,\n",
       "        -9.72758308e-02, -7.18507767e-02,  1.64841190e-01,\n",
       "        -2.18811557e-02, -1.62927508e-01, -7.88793340e-02,\n",
       "         1.05090275e-01, -8.41090977e-02,  2.76590109e-01,\n",
       "         2.88858652e-01, -1.42194062e-01, -1.01803973e-01,\n",
       "        -3.58421691e-02,  1.74887739e-02,  3.24680686e-01,\n",
       "         4.39127684e-02, -1.08765423e-01,  6.68767467e-02,\n",
       "        -3.06395143e-01, -4.40453023e-01, -9.12808776e-02,\n",
       "         2.64422774e-01, -1.17341697e-01,  2.60402206e-02,\n",
       "         2.64070809e-01,  2.37157628e-01,  5.82645535e-02,\n",
       "        -3.24947596e-01,  3.19913328e-01,  5.87294251e-03,\n",
       "        -7.32202828e-02,  3.77647936e-01,  2.84103364e-01,\n",
       "        -2.32572749e-01,  2.67499328e-01,  7.64493793e-02,\n",
       "        -2.04437792e-01, -2.42178291e-01, -3.55842486e-02,\n",
       "         5.58537319e-02, -1.58887431e-01,  9.11277439e-03,\n",
       "         1.21088549e-01,  7.37267509e-02,  1.33372679e-01,\n",
       "        -2.68057227e-01, -2.01956742e-02,  2.27327794e-02,\n",
       "        -2.45636940e-01, -1.35712981e-01,  1.80806473e-01,\n",
       "        -2.47451276e-01, -4.68687624e-01, -2.27210805e-01,\n",
       "        -2.91885227e-01, -1.28730029e-01, -9.63316336e-02,\n",
       "         3.41181934e-01,  2.47166857e-01,  3.58021632e-02,\n",
       "         1.03686340e-01,  1.53286755e-02,  3.28250974e-01,\n",
       "        -3.37787047e-02,  4.50713299e-02,  2.06174910e-01,\n",
       "        -2.11944714e-01, -5.91743961e-02, -3.91995668e-01,\n",
       "        -1.39954537e-01,  4.59998965e-01, -1.60555437e-01,\n",
       "        -1.16490141e-01,  1.19492084e-01,  1.94847256e-01,\n",
       "        -7.36181214e-02, -2.45139450e-01, -4.62856978e-01,\n",
       "        -2.07512632e-01, -9.02000070e-02,  1.24555334e-01,\n",
       "         1.87235810e-02,  1.95287809e-01,  1.47672892e-01,\n",
       "        -1.83483884e-01, -2.13453487e-01,  5.63476644e-02,\n",
       "        -3.14090811e-02,  3.07851195e-01,  6.77355304e-02,\n",
       "         2.32120350e-01,  2.48932034e-01,  2.59263247e-01,\n",
       "         2.90192872e-01,  7.48600662e-02, -4.68911529e-01,\n",
       "        -1.76959634e-01, -1.98387235e-01, -1.11569665e-01,\n",
       "        -2.55883843e-01,  3.31115886e-03, -1.47572547e-01,\n",
       "        -2.21947193e-01, -9.84760523e-02, -3.38844240e-01,\n",
       "         1.85501587e+00,  3.07810307e-01,  3.54981214e-01,\n",
       "        -3.96294147e-02,  4.81042378e-02, -1.15573600e-01,\n",
       "        -2.48289853e-03,  1.27896175e-01, -2.92316586e-01,\n",
       "         3.35364729e-01, -4.22062501e-02,  1.24823295e-01,\n",
       "         1.08728960e-01,  1.12597585e-01,  5.35209537e-01,\n",
       "         1.74036309e-01, -1.59044415e-01, -2.42335405e-02,\n",
       "        -7.70450413e-01, -1.60655096e-01, -3.28611135e-01,\n",
       "         2.02078611e-01,  5.51630378e-01,  4.18916158e-02,\n",
       "         1.69437632e-01,  2.95261085e-01,  3.60929407e-03,\n",
       "        -2.25641936e-01,  2.07068413e-01,  2.26402029e-01,\n",
       "        -1.93965018e-01, -3.14248651e-02,  1.42247021e-01,\n",
       "         1.49810299e-01, -3.92252415e-01, -3.30911428e-02,\n",
       "         6.80206344e-02, -4.03346568e-01, -2.77767211e-01,\n",
       "        -3.08147706e-02, -3.37355882e-02, -1.65858030e-01,\n",
       "         5.33886015e-01,  2.12432489e-01,  5.72598577e-02,\n",
       "         3.61782879e-01, -1.89962164e-01, -2.54004925e-01,\n",
       "         3.97928715e-01,  2.77238876e-01, -2.34172028e-02,\n",
       "         1.79163441e-02, -2.67234087e-01,  1.44152150e-01,\n",
       "         4.01676223e-02, -9.14594084e-02,  9.40600485e-02,\n",
       "        -1.19756073e-01,  1.25090882e-01,  1.86578453e-01,\n",
       "         1.65315196e-01,  2.73157328e-01,  4.32241023e-01,\n",
       "        -1.48279548e-01,  3.74825187e-02,  1.55110359e-01,\n",
       "        -4.02868539e-02, -1.74867496e-01,  1.72655165e-01,\n",
       "         3.30059826e-02,  7.93407485e-02,  2.92242348e-01,\n",
       "         1.20265424e-01,  3.49930346e-01, -1.42143905e-01,\n",
       "         3.22313569e-02,  4.54936743e-01,  1.64599232e-02,\n",
       "        -1.50991395e-01, -2.72934079e+00,  1.24384947e-01,\n",
       "         7.11515546e-02,  7.31468126e-02,  2.11962759e-02,\n",
       "         3.33792865e-01,  8.10393542e-02, -1.82311356e-01,\n",
       "         2.85602242e-01, -8.51283371e-02,  1.48794800e-01,\n",
       "         2.61924297e-01,  3.73931050e-01,  3.18932608e-02,\n",
       "         2.27714881e-01,  1.63643643e-01,  3.18864167e-01,\n",
       "         4.32122760e-02, -3.02399039e-01, -3.33344340e-01,\n",
       "        -2.59404182e-01,  2.11961195e-01, -1.22885108e-01,\n",
       "        -3.52537900e-01, -3.24120075e-01,  2.69466430e-01,\n",
       "        -7.07199946e-02, -2.18979657e-01,  1.33515745e-01,\n",
       "         1.62337422e-01, -1.60339579e-01,  3.00423563e-01,\n",
       "         1.96822584e-02,  1.55361235e-01,  2.96237953e-02,\n",
       "        -2.53081024e-01, -1.72749221e-01, -4.62899432e-02,\n",
       "         3.53452936e-02,  5.63105531e-02, -1.56049147e-01,\n",
       "         3.14447910e-01,  1.40753761e-01, -8.01199600e-02,\n",
       "         2.30557360e-02, -6.22463375e-02,  4.32745039e-01,\n",
       "        -6.05388880e-02,  1.36804074e-01, -3.59624654e-01,\n",
       "        -2.61276960e-03, -2.28369907e-02,  7.36885667e-02,\n",
       "        -1.61510631e-01,  2.30469361e-01,  2.49108989e-02,\n",
       "         1.30546659e-01, -5.71097359e-02, -3.71036157e-02,\n",
       "        -1.19941197e-01,  2.01747075e-01,  1.15222581e-01,\n",
       "         2.81837732e-01,  4.63811755e-02,  4.22710329e-01,\n",
       "        -2.70313352e-01, -1.11792535e-01,  3.67507726e-01,\n",
       "         1.30230725e-01, -7.60676526e-03, -7.44651854e-02,\n",
       "        -2.22792521e-01, -4.08750176e-02,  1.74043074e-01,\n",
       "         7.88170472e-03,  8.40618387e-02,  3.21624577e-01,\n",
       "         5.63980341e-02,  5.03681600e-02, -1.75443478e-02,\n",
       "        -2.13296279e-01,  4.05045822e-02,  4.00396669e-03,\n",
       "        -2.64720917e-01,  3.80808055e-01, -7.55112123e+00,\n",
       "        -2.18862459e-01,  6.46358132e-02, -4.00214791e-01,\n",
       "        -2.77568251e-02, -1.25513315e-01,  2.87726283e-01,\n",
       "        -1.87558830e-01,  1.30613744e-01, -2.87674367e-01,\n",
       "         2.30826735e-01,  2.40419954e-02,  2.00419128e-03,\n",
       "        -6.43426180e-02,  3.30923408e-01,  3.64211380e-01]], dtype=float32)>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0][:,0,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Decode the original sentence from the tokenizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] didnt feel humiliated [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbert_tokenizer.decode(dbert_inp['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available labels:  ['sadness' 'love' 'happy' 'fear' 'anger' 'surprise']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>gt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2168</th>\n",
       "      <td>couldnt bring blog right away mostly feel abso...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3814</th>\n",
       "      <td>eternal hope says arrive bridge finds likes fe...</td>\n",
       "      <td>love</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7834</th>\n",
       "      <td>feeling canada find prince charming</td>\n",
       "      <td>happy</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1611</th>\n",
       "      <td>remember beauty truly eye beholder people see ...</td>\n",
       "      <td>fear</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>recall high school feelings longing watched ol...</td>\n",
       "      <td>love</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text    label  gt\n",
       "2168  couldnt bring blog right away mostly feel abso...  sadness   0\n",
       "3814  eternal hope says arrive bridge finds likes fe...     love   1\n",
       "7834                feeling canada find prince charming    happy   2\n",
       "1611  remember beauty truly eye beholder people see ...     fear   3\n",
       "336   recall high school feelings longing watched ol...     love   1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Available labels: \",data.label.unique())\n",
    "num_classes = len(data.label.unique())\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  6. Create a basic NN model using DistilBERT embeddings to get the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    inps = Input(shape = (max_len,), dtype='int64')\n",
    "    masks= Input(shape = (max_len,), dtype='int64')\n",
    "    dbert_layer = dbert_model(inps, attention_mask=masks)[0][:,0,:]\n",
    "    dense = Dense(512,activation='relu',kernel_regularizer=regularizers.l2(0.01))(dbert_layer)\n",
    "    dropout= Dropout(0.5)(dense)\n",
    "    pred = Dense(num_classes, activation='softmax',kernel_regularizer=regularizers.l2(0.01))(dropout)\n",
    "    model = tf.keras.Model(inputs=[inps,masks], outputs=pred)\n",
    "    print(model.summary())\n",
    "    return model   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Feel free to add more Dense and Dropout layers with variable units and the regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 32)]                 0         []                            \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)        [(None, 32)]                 0         []                            \n",
      "                                                                                                  \n",
      " tf_distil_bert_model (TFDi  TFBaseModelOutput(last_hid   6636288   ['input_1[0][0]',             \n",
      " stilBertModel)              den_state=(None, 32, 768),   0          'input_2[0][0]']             \n",
      "                              hidden_states=None, atten                                           \n",
      "                             tions=None)                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem (  (None, 768)                  0         ['tf_distil_bert_model[0][0]']\n",
      " SlicingOpLambda)                                                                                 \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 512)                  393728    ['tf.__operators__.getitem[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " dropout_19 (Dropout)        (None, 512)                  0         ['dense[0][0]']               \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 6)                    3078      ['dropout_19[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 66759686 (254.67 MB)\n",
      "Trainable params: 66759686 (254.67 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model=create_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Prepare the model input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fotiem.constant/anaconda3/envs/ml-env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2618: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "input_ids=[]\n",
    "attention_masks=[]\n",
    "\n",
    "for sent in sentences:\n",
    "    dbert_inps=dbert_tokenizer.encode_plus(sent,add_special_tokens = True,max_length =max_len,pad_to_max_length = True,return_attention_mask = True,truncation=True)\n",
    "    input_ids.append(dbert_inps['input_ids'])\n",
    "    attention_masks.append(dbert_inps['attention_mask'])\n",
    "\n",
    "input_ids=np.asarray(input_ids)\n",
    "attention_masks=np.array(attention_masks)\n",
    "labels=np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21459, 21459, 21459)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_ids),len(attention_masks),len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Save the model input in the pickle files to use it later without performing the above steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing the pickle file.....\n"
     ]
    }
   ],
   "source": [
    "print('Preparing the pickle file.....')\n",
    "\n",
    "pickle_inp_path='./data/pickle_files/dbert_inp.pkl'\n",
    "pickle_mask_path='./data/pickle_files/dbert_mask.pkl'\n",
    "pickle_label_path='./data/pickle_files/dbert_label.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickle files saved as  ./data/pickle_files/dbert_inp.pkl ./data/pickle_files/dbert_mask.pkl ./data/pickle_files/dbert_label.pkl\n"
     ]
    }
   ],
   "source": [
    "pickle.dump((input_ids),open(pickle_inp_path,'wb'))\n",
    "pickle.dump((attention_masks),open(pickle_mask_path,'wb'))\n",
    "pickle.dump((labels),open(pickle_label_path,'wb'))\n",
    "\n",
    "\n",
    "print('Pickle files saved as ',pickle_inp_path,pickle_mask_path,pickle_label_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the saved pickle files..\n",
      "Input shape (21459, 32) Attention mask shape (21459, 32) Input label shape (21459,)\n"
     ]
    }
   ],
   "source": [
    "print('Loading the saved pickle files..')\n",
    "\n",
    "input_ids=pickle.load(open(pickle_inp_path, 'rb'))\n",
    "attention_masks=pickle.load(open(pickle_mask_path, 'rb'))\n",
    "labels=pickle.load(open(pickle_label_path, 'rb'))\n",
    "\n",
    "print('Input shape {} Attention mask shape {} Input label shape {}'.format(input_ids.shape,attention_masks.shape,labels.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values(['sadness', 'love', 'happy', 'fear', 'anger', 'surprise'])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_class_dict = dict(enumerate(data['label'].unique()))\n",
    "target_names = label_class_dict.values()\n",
    "target_names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Train Test split and setting up the loss function, accuracy and optimizer for the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train inp shape (17167, 32) Val input shape (4292, 32)\n",
      "Train label shape (17167,) Val label shape (4292,)\n",
      "Train attention mask shape (17167, 32) Val attention mask shape (4292, 32)\n"
     ]
    }
   ],
   "source": [
    "train_inp,val_inp,train_label,val_label,train_mask,val_mask=train_test_split(input_ids,labels,attention_masks,test_size=0.2)\n",
    "\n",
    "print('Train inp shape {} Val input shape {}\\nTrain label shape {} Val label shape {}\\nTrain attention mask shape {} Val attention mask shape {}'.format(train_inp.shape,val_inp.shape,train_label.shape,val_label.shape,train_mask.shape,val_mask.shape))\n",
    "\n",
    "\n",
    "log_dir='dbert_model'\n",
    "model_save_path='./dbert_model.h5'\n",
    "\n",
    "callbacks = [tf.keras.callbacks.ModelCheckpoint(filepath=model_save_path,save_weights_only=True,monitor='val_loss',mode='min',save_best_only=True),keras.callbacks.TensorBoard(log_dir=log_dir)]\n",
    "\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5)\n",
    "\n",
    "model.compile(loss=loss,optimizer=optimizer, metrics=[metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks= [tf.keras.callbacks.ModelCheckpoint(filepath=model_save_path,save_weights_only=True,monitor='val_loss',mode='min',save_best_only=True),keras.callbacks.TensorBoard(log_dir=log_dir)]\n",
    "model.compile(loss=loss,optimizer=optimizer, metrics=[metric])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1073/1073 [==============================] - 362s 337ms/step - loss: 2.9789 - accuracy: 0.9395 - val_loss: 2.2257 - val_accuracy: 0.9259\n",
      "Epoch 2/5\n",
      "1073/1073 [==============================] - 352s 328ms/step - loss: 1.6627 - accuracy: 0.9505 - val_loss: 1.2750 - val_accuracy: 0.9301\n",
      "Epoch 3/5\n",
      "1073/1073 [==============================] - 349s 326ms/step - loss: 0.9401 - accuracy: 0.9575 - val_loss: 0.7862 - val_accuracy: 0.9275\n",
      "Epoch 4/5\n",
      "1073/1073 [==============================] - 355s 331ms/step - loss: 0.5473 - accuracy: 0.9631 - val_loss: 0.5131 - val_accuracy: 0.9275\n",
      "Epoch 5/5\n",
      "1073/1073 [==============================] - 363s 338ms/step - loss: 0.3492 - accuracy: 0.9681 - val_loss: 0.3872 - val_accuracy: 0.9292\n"
     ]
    }
   ],
   "source": [
    "history=model.fit([train_inp,train_mask],train_label,batch_size=16,epochs=5,validation_data=([val_inp,val_mask],val_label),callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboard visualization (Training-Testing curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 42543), started 0:37:09 ago. (Use '!kill 42543' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-1a76eddee7f6ee21\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-1a76eddee7f6ee21\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir {log_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will Increase the number of epochs in order to decrease the loss further\n",
    "Here we will use the saved model for predictions and calculating the evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)        [(None, 32)]                 0         []                            \n",
      "                                                                                                  \n",
      " input_6 (InputLayer)        [(None, 32)]                 0         []                            \n",
      "                                                                                                  \n",
      " tf_distil_bert_model (TFDi  TFBaseModelOutput(last_hid   6636288   ['input_5[0][0]',             \n",
      " stilBertModel)              den_state=(None, 32, 768),   0          'input_6[0][0]']             \n",
      "                              hidden_states=None, atten                                           \n",
      "                             tions=None)                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_2  (None, 768)                  0         ['tf_distil_bert_model[2][0]']\n",
      "  (SlicingOpLambda)                                                                               \n",
      "                                                                                                  \n",
      " dense_4 (Dense)             (None, 512)                  393728    ['tf.__operators__.getitem_2[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " dropout_21 (Dropout)        (None, 512)                  0         ['dense_4[0][0]']             \n",
      "                                                                                                  \n",
      " dense_5 (Dense)             (None, 6)                    3078      ['dropout_21[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 66759686 (254.67 MB)\n",
      "Trainable params: 66759686 (254.67 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "trained_model = create_model()\n",
    "trained_model.compile(loss=loss,optimizer=optimizer, metrics=[metric])\n",
    "trained_model.load_weights(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269/269 [==============================] - 31s 106ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9288570145902261"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = trained_model.predict([val_inp,val_mask],batch_size=16)\n",
    "pred_labels = preds.argmax(axis=1)\n",
    "f1 = f1_score(val_label, pred_labels, average='weighted')\n",
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_values(['sadness', 'love', 'happy', 'fear', 'anger', 'surprise'])\n",
      "(4292,)\n",
      "(4292,)\n",
      "F1 score: 0.9288570145902261\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.97      1287\n",
      "           1       0.82      0.82      0.82       326\n",
      "           2       0.94      0.94      0.94      1365\n",
      "           3       0.89      0.94      0.91       545\n",
      "           4       0.97      0.89      0.93       603\n",
      "           5       0.85      0.77      0.81       166\n",
      "\n",
      "    accuracy                           0.93      4292\n",
      "   macro avg       0.90      0.89      0.90      4292\n",
      "weighted avg       0.93      0.93      0.93      4292\n",
      "\n",
      "Training and saving built model...\n"
     ]
    }
   ],
   "source": [
    "print(target_names)\n",
    "# print(target_names.shape)\n",
    "print(val_label.shape)\n",
    "print(pred_labels.shape)\n",
    "\n",
    "\n",
    "# we print F1 score and classification report\n",
    "print('F1 score:', f1)\n",
    "print('Classification Report:')\n",
    "print(classification_report(val_label, pred_labels))\n",
    "\n",
    "print('Training and saving built model...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick test in real world scenario\n",
    "We are now gonna try to predict a sentence with any input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we try to predict the label of a random sentence from user\n",
    "def predict(sentence):\n",
    "    # we first preprocess the sentence\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "    # then we do some tokenization on the sentence\n",
    "    dbert_inps=dbert_tokenizer.encode_plus(sentence,add_special_tokens = True,max_length =max_len,pad_to_max_length = True,return_attention_mask = True,truncation=True)\n",
    "    # then we convert to numpy array\n",
    "    id_inp=np.asarray(dbert_inps['input_ids'])\n",
    "    mask_inp=np.asarray(dbert_inps['attention_mask'])\n",
    "    # and predict the label using the trained model\n",
    "    pred = trained_model.predict([id_inp.reshape(1,-1),mask_inp.reshape(1,-1)])\n",
    "    # and then get the label with the highest probability\n",
    "    pred_label = np.argmax(pred,axis=1)\n",
    "    # we then return it\n",
    "    return label_class_dict[pred_label[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 354ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'anger'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test the model on a random sentence\n",
    "predict(\"It is a love hate relationship between me and my father\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
