{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emotion classification with BERT\n",
    "\n",
    "This notebook focuses on classifying text with emotions using the BERT transformer model. The goal is to analyze and understand the emotions conveyed in textual data.\n",
    "\n",
    "By Constant Fotie Moghommahie\n",
    "\n",
    "[fotiecodes](https://fotiecodes.com).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classes: \n",
    "```json {\n",
    "    'sadness': 0,\n",
    "    'fear': 1,\n",
    "    'anger': 2,\n",
    "    'love': 3,\n",
    "    'happy': 4,\n",
    "    'surprise': 5\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import and install neccessary libs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /Users/fotiem.constant/.pyenv/versions/3.10.6/lib/python3.10/site-packages (3.8.1)\n",
      "Requirement already satisfied: tqdm in /Users/fotiem.constant/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from nltk) (4.66.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/fotiem.constant/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from nltk) (2023.10.3)\n",
      "Requirement already satisfied: click in /Users/fotiem.constant/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /Users/fotiem.constant/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from nltk) (1.3.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: tensorflow in /Users/fotiem.constant/.pyenv/versions/3.10.6/lib/python3.10/site-packages (2.15.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/fotiem.constant/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from tensorflow) (16.0.6)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/fotiem.constant/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/fotiem.constant/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/fotiem.constant/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from tensorflow) (0.34.0)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Users/fotiem.constant/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from tensorflow) (0.5.4)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in /Users/fotiem.constant/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: setuptools in /Users/fotiem.constant/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from tensorflow) (63.2.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/fotiem.constant/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from tensorflow) (1.59.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/fotiem.constant/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /Users/fotiem.constant/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/fotiem.constant/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from tensorflow) (1.4.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Users/fotiem.constant/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from tensorflow) (3.20.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /Users/fotiem.constant/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from tensorflow) (23.5.26)\n",
      "Requirement already satisfied: packaging in /Users/fotiem.constant/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from tensorflow) (23.2)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/fotiem.constant/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from tensorflow) (4.8.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/fotiem.constant/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /Users/fotiem.constant/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from tensorflow) (2.15.0)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in /Users/fotiem.constant/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from tensorflow) (2.15.0)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in /Users/fotiem.constant/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from tensorflow) (2.15.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/fotiem.constant/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /Users/fotiem.constant/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from tensorflow) (1.26.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Users/fotiem.constant/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from tensorflow) (3.10.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/fotiem.constant/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.41.3)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/fotiem.constant/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.23.4)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/fotiem.constant/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /Users/fotiem.constant/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/fotiem.constant/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/fotiem.constant/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/fotiem.constant/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/fotiem.constant/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/fotiem.constant/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/fotiem.constant/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/fotiem.constant/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/fotiem.constant/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/fotiem.constant/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/fotiem.constant/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/fotiem.constant/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/fotiem.constant/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /Users/fotiem.constant/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/fotiem.constant/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install nltk\n",
    "!pip3 install --upgrade tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#import tensorflow_hub as hub\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import re\n",
    "import unicodedata\n",
    "from nltk.corpus import stopwords\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense,Dropout, Input\n",
    "#from tqdm import tqdm\n",
    "import pickle\n",
    "from sklearn.metrics import confusion_matrix,f1_score,classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/fotiem.constant/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, TFBertModel, BertConfig,TFDistilBertModel,DistilBertTokenizer,DistilBertConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.  Preprocessing and cleaning functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unicode_to_ascii(s):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "def clean_stopwords_shortwords(w):\n",
    "    stopwords_list=stopwords.words('english')\n",
    "    words = w.split() \n",
    "    clean_words = [word for word in words if (word not in stopwords_list) and len(word) > 2]\n",
    "    return \" \".join(clean_words) \n",
    "\n",
    "def preprocess_sentence(w):\n",
    "    w = unicode_to_ascii(w.lower().strip())\n",
    "    w = re.sub(r\"([?.!,¿])\", r\" \", w)\n",
    "    w = re.sub(r'[\" \"]+', \" \", w)\n",
    "    w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
    "    w=clean_stopwords_shortwords(w)\n",
    "    w=re.sub(r'@\\w+', '',w)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Load and Inspect our dataset\n",
    "We will first load and and preview our dataset. So we can check for any missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Emotion\n",
       "0                            i didnt feel humiliated  sadness\n",
       "1  i can go from feeling so hopeless to so damned...  sadness\n",
       "2   im grabbing a minute to post i feel greedy wrong    anger\n",
       "3  i am ever feeling nostalgic about the fireplac...     love\n",
       "4                               i am feeling grouchy    anger"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load and inspect the new dataset\n",
    "data_file = './data/emotion_final.csv'\n",
    "\n",
    "# Read the data from the CSV file into a pandas DataFrame\n",
    "data=pd.read_csv(data_file,encoding='ISO-8859-1')\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">  Removing Unnamed Columns, dropping NaN data and resetting the index after dropping some rows/columns containing NaN dataset and finally shuffling the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File has 21459 rows and 2 columns\n",
      "File has 21459 rows and 2 columns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16084</th>\n",
       "      <td>i came home waiting for the shower read someth...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8328</th>\n",
       "      <td>i am mostly feeling contentedly terrified abou...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13309</th>\n",
       "      <td>i cant help but feel someones going to end up ...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>im feeling low and forgotten</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7336</th>\n",
       "      <td>i was like that i always wanted to feel and be...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  Emotion\n",
       "16084  i came home waiting for the shower read someth...  sadness\n",
       "8328   i am mostly feeling contentedly terrified abou...     fear\n",
       "13309  i cant help but feel someones going to end up ...    anger\n",
       "933                         im feeling low and forgotten  sadness\n",
       "7336   i was like that i always wanted to feel and be...     love"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('File has {} rows and {} columns'.format(data.shape[0],data.shape[1]))\n",
    "data=data.dropna()\n",
    "data=data.reset_index(drop=True)\n",
    "print('File has {} rows and {} columns'.format(data.shape[0],data.shape[1]))\n",
    "data = shuffle(data)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>gt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16084</th>\n",
       "      <td>came home waiting shower read something made u...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8328</th>\n",
       "      <td>mostly feeling contentedly terrified</td>\n",
       "      <td>fear</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13309</th>\n",
       "      <td>cant help feel someones going end pissed</td>\n",
       "      <td>anger</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>feeling low forgotten</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7336</th>\n",
       "      <td>like always wanted feel accepted family others</td>\n",
       "      <td>love</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text    label  gt\n",
       "16084  came home waiting shower read something made u...  sadness   0\n",
       "8328                mostly feeling contentedly terrified     fear   1\n",
       "13309           cant help feel someones going end pissed    anger   2\n",
       "933                                feeling low forgotten  sadness   0\n",
       "7336      like always wanted feel accepted family others     love   3"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=data.rename(columns = {'Emotion': 'label', 'Text': 'text'}, inplace = False)\n",
    "\n",
    "# Ensure all unique labels are included in the mapping dictionary\n",
    "unique_labels = data['label'].unique()\n",
    "mapping_dict = {label: index for index, label in enumerate(unique_labels)}\n",
    "\n",
    "data['gt'] = data['label'].map(mapping_dict)\n",
    "\n",
    "# Fill NaN values with a specific value (e.g., -1) and convert to integer\n",
    "data['gt'] = data['gt'].fillna(-1).astype(int)\n",
    "\n",
    "data['text']=data['text'].map(preprocess_sentence)\n",
    "\n",
    "num_classes=len(data.label.unique())\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  4. Loading DistilBERT Tokenizer and the DistilBERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbert_tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['vocab_transform', 'vocab_projector', 'activation_13', 'vocab_layer_norm']\n",
      "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "dbert_model = TFDistilBertModel.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  5. Preparing input for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21459, 21459)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the maximum length of the input sentences\n",
    "max_len = 32\n",
    "\n",
    "# Get the sentences and labels from the data\n",
    "sentences = data['text']\n",
    "labels = data['gt']\n",
    "\n",
    "# Print the length of the sentences and labels\n",
    "len(sentences), len(labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Let's take a sentence from the dataset and understand the input and output of the DistilBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'didnt feel humiliated'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['didn', '##t', 'feel', 'humiliated']"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbert_tokenizer.tokenize(sentences[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Input ids and the attention masks from the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fotiem.constant/.pyenv/versions/3.10.6/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2285: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 2134, 2102, 2514, 26608, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbert_inp=dbert_tokenizer.encode_plus(sentences[0],add_special_tokens = True,max_length =20,pad_to_max_length = True,truncation=True)\n",
    "dbert_inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 2134, 2102, 2514, 26608, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbert_inp['input_ids']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">  DistilBERT model output: Give input_ids and the attention_mask obtained from the tokenizer. The output will be a tuple of the size (1,max_len,768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(transformers.modeling_tf_outputs.TFBaseModelOutput,\n",
       " TFBaseModelOutput(last_hidden_state=<tf.Tensor: shape=(1, 20, 768), dtype=float32, numpy=\n",
       " array([[[-0.17138529,  0.04808471, -0.11152925, ..., -0.06434252,\n",
       "           0.330923  ,  0.3642112 ],\n",
       "         [ 0.35398188,  0.23759897,  0.2169984 , ...,  0.00849794,\n",
       "           0.46305764, -0.41722077],\n",
       "         [-0.4177962 ,  0.0801597 ,  0.4836896 , ..., -0.17692414,\n",
       "           0.5626385 ,  0.43658397],\n",
       "         ...,\n",
       "         [-0.15297796,  0.03547437,  0.06371675, ...,  0.03469756,\n",
       "           0.02733814, -0.16189006],\n",
       "         [-0.14419688,  0.06348484,  0.07919805, ...,  0.11205959,\n",
       "           0.04838258, -0.20951843],\n",
       "         [-0.1142126 ,  0.06052709,  0.07216727, ...,  0.12287258,\n",
       "           0.0578858 , -0.19464062]]], dtype=float32)>, hidden_states=None, attentions=None))"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_inp=np.asarray(dbert_inp['input_ids'])\n",
    "mask_inp=np.asarray(dbert_inp['attention_mask'])\n",
    "out=dbert_model([id_inp.reshape(1,-1),mask_inp.reshape(1,-1)])\n",
    "type(out),out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Obtain the embeddings of a sentence from the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 768), dtype=float32, numpy=\n",
       "array([[-1.71385288e-01,  4.80847135e-02, -1.11529246e-01,\n",
       "        -2.09110361e-02, -2.34398529e-01, -4.43109423e-02,\n",
       "         2.90086329e-01,  2.66656995e-01,  2.05920771e-01,\n",
       "        -2.20593363e-01,  5.82960322e-02, -2.02091962e-01,\n",
       "        -1.94992989e-01,  1.50783703e-01,  9.85642374e-02,\n",
       "         5.78699633e-02,  2.98273973e-02,  1.51283860e-01,\n",
       "         6.53597992e-03, -5.72893135e-02, -7.78305829e-02,\n",
       "        -3.38845789e-01, -1.36250705e-01,  7.62559399e-02,\n",
       "        -1.06427193e-01,  3.59944515e-02,  1.48689240e-01,\n",
       "        -3.07668000e-01,  6.57812208e-02, -1.10575132e-01,\n",
       "         6.58358634e-02,  2.32130259e-01, -1.61469787e-01,\n",
       "         2.03128271e-02, -1.84822604e-01,  1.77118883e-01,\n",
       "         3.92266028e-02,  1.18414506e-01,  1.43307328e-01,\n",
       "         1.92268342e-02, -2.72444606e-01, -5.23971878e-02,\n",
       "        -2.44558007e-01, -4.83159050e-02,  1.09537043e-01,\n",
       "        -1.48615271e-01, -2.21261787e+00, -3.53778973e-02,\n",
       "        -3.09246689e-01, -5.51777631e-02,  3.77840012e-01,\n",
       "        -1.60714790e-01,  1.36903971e-01,  2.55552471e-01,\n",
       "        -3.15836668e-02,  3.86985064e-01, -2.13476270e-01,\n",
       "         2.70366967e-01,  2.19966248e-02,  1.20392181e-01,\n",
       "         1.89636469e-01,  2.10117206e-01, -2.26430193e-01,\n",
       "         4.09133732e-02, -5.76001592e-02,  2.83537567e-01,\n",
       "        -1.17895372e-01,  4.58773464e-01, -2.02765584e-01,\n",
       "         2.75058538e-01, -2.53737867e-01, -2.13359773e-01,\n",
       "         2.41958335e-01,  3.00892256e-02,  2.36203849e-01,\n",
       "        -1.02853209e-01,  1.36531722e-02, -7.87594542e-02,\n",
       "        -1.16304949e-01,  2.83179045e-01,  4.35257629e-02,\n",
       "         3.33483249e-01,  1.19095817e-01,  2.50336945e-01,\n",
       "         6.08269423e-02,  1.56001329e-01, -1.33856326e-01,\n",
       "        -1.35659903e-01,  2.31804684e-01,  2.31329337e-01,\n",
       "        -6.94522187e-02, -1.00743413e-01,  1.64541155e-01,\n",
       "         1.07205562e-01,  1.72117665e-01, -2.30545387e-01,\n",
       "         6.52416050e-02, -6.39440268e-02,  4.12915885e-01,\n",
       "         1.95158243e-01,  7.50754327e-02, -1.60083249e-01,\n",
       "        -1.20999888e-02, -3.00561905e-01, -1.73728943e-01,\n",
       "        -6.42001033e-02, -1.13449648e-01, -3.18935901e-01,\n",
       "         1.10170133e-02, -2.48620868e+00,  2.39081636e-01,\n",
       "         1.17219612e-01, -1.13289580e-01, -4.75271463e-01,\n",
       "        -7.78911859e-02,  4.97977227e-01,  3.31521213e-01,\n",
       "        -7.51518458e-02, -1.25041157e-01, -4.47303355e-02,\n",
       "         5.14969267e-02,  1.76549077e-01,  1.51390433e-01,\n",
       "        -8.48705471e-02, -5.30066080e-02,  1.39040172e-01,\n",
       "         5.40546998e-02, -1.87353671e-01,  5.42767420e-02,\n",
       "         2.23130062e-01,  2.74579048e-01,  4.20294225e-01,\n",
       "        -4.53176685e-02,  1.08983368e-01, -3.78529310e-01,\n",
       "         6.30203933e-02,  1.46910787e-01, -8.19530264e-02,\n",
       "        -8.61302391e-02, -2.16236427e-01, -2.02109322e-01,\n",
       "         3.14534828e-02, -2.81477499e+00,  3.04785699e-01,\n",
       "         4.89276946e-01, -1.44295394e-04,  1.53729945e-01,\n",
       "         6.45869151e-02, -2.91423202e-02,  1.34964496e-01,\n",
       "         1.05309270e-01,  1.89804852e-01, -1.63518071e-01,\n",
       "        -1.12996008e-02, -2.39062026e-01,  1.60336986e-01,\n",
       "        -2.04974025e-01,  1.13692805e-01,  4.03580755e-01,\n",
       "         2.52417833e-01,  1.91249438e-02, -1.53147951e-01,\n",
       "        -9.98562574e-02, -3.09815630e-02,  6.90933466e-02,\n",
       "         6.85140863e-02,  5.48529662e-02,  1.76367089e-01,\n",
       "         2.42069796e-01, -1.32107019e-01,  1.28133357e-01,\n",
       "        -1.20569900e-01,  3.40107262e-01, -1.00989401e-01,\n",
       "         1.06453955e-01, -1.59793079e-01,  2.98378289e-01,\n",
       "         2.19960034e-01, -1.42658800e-01,  4.52695340e-02,\n",
       "        -2.40304500e-01,  2.96431661e-01,  6.20560981e-02,\n",
       "         4.34369966e-02,  1.01894572e-01,  1.38625234e-01,\n",
       "         2.96794355e-01, -3.64211947e-01, -9.96032953e-02,\n",
       "         2.87841946e-01, -3.66397589e-01, -2.27272615e-01,\n",
       "        -1.92059293e-01,  7.08744228e-02,  3.77417296e-01,\n",
       "        -2.24603891e-01, -3.78496535e-02, -2.90221810e-01,\n",
       "         1.93442076e-01,  5.13495654e-02, -1.84562445e-01,\n",
       "        -3.44921708e-01, -5.88605553e-02,  2.38372862e-01,\n",
       "         5.29500470e-03,  3.55634356e+00, -8.14669877e-02,\n",
       "        -2.42045283e-01,  1.77641928e-01,  3.14604133e-01,\n",
       "        -4.86690812e-02, -6.46351874e-02, -6.48584142e-02,\n",
       "        -8.25561956e-03,  2.61278041e-02, -8.71599019e-02,\n",
       "         2.52242208e-01, -1.81538492e-01, -3.18681262e-02,\n",
       "        -4.62386711e-03,  2.31858611e-01, -8.62367153e-02,\n",
       "        -4.75835428e-02,  6.43613935e-03, -1.39836565e-01,\n",
       "         2.20672891e-01,  1.25310481e-01,  1.48932457e-01,\n",
       "        -5.90122752e-02, -1.38019979e+00, -1.29714206e-01,\n",
       "        -1.50800467e-01,  4.09858450e-02,  3.03183168e-01,\n",
       "        -2.41809636e-01, -5.37861958e-02,  1.73012629e-01,\n",
       "        -1.19099580e-03,  2.15847082e-02,  1.07249752e-01,\n",
       "        -2.44866163e-01,  1.98535487e-01,  4.09471482e-01,\n",
       "         2.19657779e-01, -3.52734536e-01,  3.82150203e-01,\n",
       "         4.44890797e-01, -2.69476194e-02,  9.17765498e-02,\n",
       "        -5.72810099e-02,  3.19885999e-01, -9.80715305e-02,\n",
       "        -1.03323393e-01, -1.66089430e-01,  1.78673044e-02,\n",
       "        -1.55722216e-01,  1.63337409e-01, -4.86560091e-02,\n",
       "        -2.63091922e-01, -2.52352148e-01, -9.61504877e-02,\n",
       "         1.46085054e-01,  3.63961458e-01,  2.40882814e-01,\n",
       "        -2.16162652e-01, -1.83926731e-01,  1.20740563e-01,\n",
       "        -2.18235001e-01,  2.73817271e-01,  8.92957300e-02,\n",
       "        -1.58060417e-02, -9.44469348e-02, -2.49686092e-01,\n",
       "        -3.59411073e+00, -1.51947320e-01,  1.03521004e-01,\n",
       "         3.58736992e-01,  3.87253076e-01, -1.71166152e-01,\n",
       "        -4.28579934e-02,  6.93484098e-02,  4.07407194e-01,\n",
       "        -5.23736596e-01,  3.78721595e-01,  2.74168074e-01,\n",
       "         9.66792405e-02,  1.14795804e-01, -3.94072652e-01,\n",
       "         2.91701108e-01, -1.59666926e-01, -3.21381278e-02,\n",
       "         3.88063379e-02,  1.40456378e-01, -2.51044352e-02,\n",
       "         3.09824705e-01, -7.11085834e-03,  4.54305410e-02,\n",
       "        -2.57156044e-03,  1.63144842e-01,  1.16625324e-01,\n",
       "        -2.95956075e-01,  1.01469830e-02, -7.55886883e-02,\n",
       "         5.97733930e-02, -2.56760120e-01,  1.20577499e-01,\n",
       "        -5.60368411e-02, -1.59052238e-01, -2.65954041e+00,\n",
       "        -2.29781777e-01,  1.45233199e-01, -1.83815747e-01,\n",
       "         1.92415386e-01, -1.16836540e-01,  2.17756063e-01,\n",
       "        -1.73737317e-01, -3.16536903e-01,  1.93932027e-01,\n",
       "         2.58156121e-01, -3.10992658e-01,  1.93742409e-01,\n",
       "         2.32987702e-01,  4.71677184e-01, -1.01609528e-02,\n",
       "         3.46234798e-01, -4.30719703e-01,  2.54909694e-03,\n",
       "         1.82718605e-01, -1.05708092e-03, -6.88091964e-02,\n",
       "        -5.39686233e-02, -2.02291042e-01,  1.49459749e-01,\n",
       "         5.08890152e-01, -3.04890811e-01,  6.92824125e-02,\n",
       "        -2.15019062e-01, -3.91285941e-02, -2.74564102e-02,\n",
       "        -1.54505834e-01,  5.77239953e-02,  1.33657619e-01,\n",
       "        -4.13258709e-02, -2.73490131e-01,  1.52299792e-01,\n",
       "         1.30426615e-01,  2.09828645e-01,  1.28479972e-02,\n",
       "        -5.71454875e-02,  3.03664923e-01, -8.40176642e-03,\n",
       "         1.83006316e-01,  3.68612617e-01,  7.40124285e-02,\n",
       "        -1.05772607e-01, -2.69602865e-01, -1.17974311e-01,\n",
       "         1.98808044e-01, -2.49158256e-02,  1.38784960e-01,\n",
       "         1.13749599e+00, -5.86784631e-02,  2.78955430e-01,\n",
       "        -1.70916647e-01,  9.82150659e-02,  1.83147788e-01,\n",
       "        -6.10213950e-02, -3.21691521e-02,  1.98484302e-01,\n",
       "         1.77197084e-02,  2.12275758e-02, -1.02969315e-02,\n",
       "        -3.81246582e-02, -1.61226422e-01,  4.82719615e-02,\n",
       "        -2.66769469e-01,  1.20724700e-02,  3.27195585e-01,\n",
       "        -1.95993576e-02,  1.44174248e-01,  1.87638961e-02,\n",
       "        -8.77612352e-01, -2.92940855e-01,  3.56066823e-01,\n",
       "        -1.42777845e-01, -1.39469191e-01, -7.02299923e-02,\n",
       "        -3.56428251e-02, -3.60453397e-01,  4.52016015e-03,\n",
       "        -1.49296075e-01,  1.12126313e-01, -2.02312857e-01,\n",
       "         9.66564100e-03, -3.91345918e-02,  5.31731583e-02,\n",
       "        -3.76352698e-01, -1.09152719e-01,  7.60202855e-02,\n",
       "         2.76892930e-01,  1.93607554e-01,  2.53630996e-01,\n",
       "         8.06428939e-02, -5.21415249e-02,  3.21765453e-01,\n",
       "        -6.31081283e-01,  6.22725263e-02, -2.56033063e-01,\n",
       "        -5.66750914e-02, -3.12876225e-01, -2.14644805e-01,\n",
       "         1.04577817e-01, -2.64344603e-01, -1.48782820e-01,\n",
       "        -4.35317695e-01,  3.67390364e-01, -5.81243038e-02,\n",
       "         2.19410732e-01, -6.16730303e-02,  8.76497850e-02,\n",
       "        -3.52052003e-02,  2.96966195e-01,  9.28598225e-01,\n",
       "        -2.29679555e-01,  8.33446085e-02,  3.37287188e-01,\n",
       "         2.19597891e-02,  4.22581702e-01,  3.17786872e-01,\n",
       "         2.10245192e-01, -2.38254070e-01, -9.85662490e-02,\n",
       "        -1.88133746e-01,  1.28842920e-01, -3.00585050e-02,\n",
       "        -3.93236548e-01, -3.66457254e-01, -1.99069411e-01,\n",
       "         4.11940098e-01,  7.27879182e-02, -2.62691557e-01,\n",
       "        -5.77453494e-01,  1.00617044e-01, -3.60695481e-01,\n",
       "        -1.52787231e-02,  8.65643993e-02,  5.47448918e-02,\n",
       "         1.14691377e-01,  3.25779736e-01,  2.60382332e-02,\n",
       "        -2.19637379e-01,  2.81936198e-01, -9.00079608e-02,\n",
       "         4.51919466e-01, -8.02426785e-03, -2.32060194e-01,\n",
       "        -3.45115438e-02,  5.30513287e-01, -9.02970210e-02,\n",
       "        -3.10162902e-01,  1.36168092e-01, -1.40956849e-01,\n",
       "         2.43669033e-01,  8.92601013e-02, -3.08478139e-02,\n",
       "        -1.10532820e-01, -1.34520024e-01, -1.61218792e-01,\n",
       "        -1.10280709e-02,  1.34611309e-01, -1.33931947e+00,\n",
       "         4.22265291e-01,  3.25056106e-01, -2.78467119e-01,\n",
       "         2.63327122e-01, -1.69588149e-01, -3.21623355e-01,\n",
       "         3.13937724e-01,  2.21853271e-01,  6.70593977e-03,\n",
       "         3.84416021e-02,  1.77361593e-02, -1.75623551e-01,\n",
       "        -9.72760767e-02, -7.18508437e-02,  1.64841160e-01,\n",
       "        -2.18810663e-02, -1.62927091e-01, -7.88795501e-02,\n",
       "         1.05090246e-01, -8.41087848e-02,  2.76590258e-01,\n",
       "         2.88858265e-01, -1.42194003e-01, -1.01804286e-01,\n",
       "        -3.58420797e-02,  1.74889974e-02,  3.24680775e-01,\n",
       "         4.39129360e-02, -1.08765334e-01,  6.68763742e-02,\n",
       "        -3.06394964e-01, -4.40452784e-01, -9.12807733e-02,\n",
       "         2.64422774e-01, -1.17341973e-01,  2.60403454e-02,\n",
       "         2.64070868e-01,  2.37157732e-01,  5.82646504e-02,\n",
       "        -3.24947774e-01,  3.19912851e-01,  5.87328523e-03,\n",
       "        -7.32201934e-02,  3.77648383e-01,  2.84103334e-01,\n",
       "        -2.32572928e-01,  2.67499864e-01,  7.64493495e-02,\n",
       "        -2.04438120e-01, -2.42178276e-01, -3.55843082e-02,\n",
       "         5.58538251e-02, -1.58887506e-01,  9.11269430e-03,\n",
       "         1.21088758e-01,  7.37268627e-02,  1.33372650e-01,\n",
       "        -2.68057287e-01, -2.01957710e-02,  2.27324516e-02,\n",
       "        -2.45636478e-01, -1.35712922e-01,  1.80806667e-01,\n",
       "        -2.47451574e-01, -4.68687654e-01, -2.27211058e-01,\n",
       "        -2.91885018e-01, -1.28730074e-01, -9.63313505e-02,\n",
       "         3.41182172e-01,  2.47166991e-01,  3.58022861e-02,\n",
       "         1.03686430e-01,  1.53287128e-02,  3.28250617e-01,\n",
       "        -3.37785855e-02,  4.50711958e-02,  2.06174925e-01,\n",
       "        -2.11944610e-01, -5.91747612e-02, -3.91995519e-01,\n",
       "        -1.39954582e-01,  4.59999025e-01, -1.60555676e-01,\n",
       "        -1.16489798e-01,  1.19492441e-01,  1.94847167e-01,\n",
       "        -7.36182332e-02, -2.45139286e-01, -4.62857068e-01,\n",
       "        -2.07512841e-01, -9.01998878e-02,  1.24555185e-01,\n",
       "         1.87239386e-02,  1.95287794e-01,  1.47673205e-01,\n",
       "        -1.83483839e-01, -2.13453829e-01,  5.63477799e-02,\n",
       "        -3.14095691e-02,  3.07850957e-01,  6.77353591e-02,\n",
       "         2.32120454e-01,  2.48931780e-01,  2.59263217e-01,\n",
       "         2.90192783e-01,  7.48600960e-02, -4.68911439e-01,\n",
       "        -1.76959783e-01, -1.98387414e-01, -1.11569390e-01,\n",
       "        -2.55883783e-01,  3.31121823e-03, -1.47572249e-01,\n",
       "        -2.21947074e-01, -9.84763950e-02, -3.38844299e-01,\n",
       "         1.85501564e+00,  3.07810247e-01,  3.54981184e-01,\n",
       "        -3.96293327e-02,  4.81047928e-02, -1.15573741e-01,\n",
       "        -2.48343125e-03,  1.27896369e-01, -2.92316884e-01,\n",
       "         3.35364938e-01, -4.22062576e-02,  1.24823228e-01,\n",
       "         1.08728766e-01,  1.12597570e-01,  5.35209656e-01,\n",
       "         1.74036130e-01, -1.59044445e-01, -2.42339727e-02,\n",
       "        -7.70450890e-01, -1.60654873e-01, -3.28611463e-01,\n",
       "         2.02078462e-01,  5.51630735e-01,  4.18916494e-02,\n",
       "         1.69437572e-01,  2.95260936e-01,  3.60923260e-03,\n",
       "        -2.25642234e-01,  2.07068339e-01,  2.26402193e-01,\n",
       "        -1.93965599e-01, -3.14245373e-02,  1.42246917e-01,\n",
       "         1.49810180e-01, -3.92252624e-01, -3.30915116e-02,\n",
       "         6.80209622e-02, -4.03346509e-01, -2.77767420e-01,\n",
       "        -3.08150202e-02, -3.37351859e-02, -1.65858135e-01,\n",
       "         5.33886433e-01,  2.12432712e-01,  5.72602302e-02,\n",
       "         3.61782551e-01, -1.89962000e-01, -2.54005015e-01,\n",
       "         3.97928625e-01,  2.77239382e-01, -2.34167725e-02,\n",
       "         1.79167688e-02, -2.67234325e-01,  1.44152403e-01,\n",
       "         4.01676409e-02, -9.14597586e-02,  9.40601900e-02,\n",
       "        -1.19756117e-01,  1.25090733e-01,  1.86578423e-01,\n",
       "         1.65315360e-01,  2.73157150e-01,  4.32241291e-01,\n",
       "        -1.48279428e-01,  3.74827981e-02,  1.55110091e-01,\n",
       "        -4.02868316e-02, -1.74867332e-01,  1.72655344e-01,\n",
       "         3.30059454e-02,  7.93403536e-02,  2.92242527e-01,\n",
       "         1.20265335e-01,  3.49929690e-01, -1.42143756e-01,\n",
       "         3.22311297e-02,  4.54936534e-01,  1.64602902e-02,\n",
       "        -1.50991395e-01, -2.72933912e+00,  1.24384835e-01,\n",
       "         7.11516291e-02,  7.31467754e-02,  2.11962089e-02,\n",
       "         3.33793283e-01,  8.10399503e-02, -1.82311326e-01,\n",
       "         2.85602391e-01, -8.51285756e-02,  1.48794934e-01,\n",
       "         2.61924207e-01,  3.73931020e-01,  3.18929367e-02,\n",
       "         2.27714688e-01,  1.63643718e-01,  3.18864316e-01,\n",
       "         4.32124808e-02, -3.02399516e-01, -3.33343893e-01,\n",
       "        -2.59403914e-01,  2.11961985e-01, -1.22884847e-01,\n",
       "        -3.52537721e-01, -3.24120373e-01,  2.69466549e-01,\n",
       "        -7.07199275e-02, -2.18979254e-01,  1.33515924e-01,\n",
       "         1.62337929e-01, -1.60339504e-01,  3.00423563e-01,\n",
       "         1.96821243e-02,  1.55361444e-01,  2.96238065e-02,\n",
       "        -2.53081441e-01, -1.72749549e-01, -4.62898873e-02,\n",
       "         3.53453085e-02,  5.63107245e-02, -1.56049341e-01,\n",
       "         3.14448088e-01,  1.40753895e-01, -8.01196918e-02,\n",
       "         2.30554380e-02, -6.22462630e-02,  4.32744682e-01,\n",
       "        -6.05389848e-02,  1.36804327e-01, -3.59625131e-01,\n",
       "        -2.61332095e-03, -2.28369683e-02,  7.36885965e-02,\n",
       "        -1.61510974e-01,  2.30470031e-01,  2.49109678e-02,\n",
       "         1.30546406e-01, -5.71098551e-02, -3.71033624e-02,\n",
       "        -1.19941108e-01,  2.01746956e-01,  1.15223095e-01,\n",
       "         2.81837344e-01,  4.63811010e-02,  4.22710240e-01,\n",
       "        -2.70313054e-01, -1.11792304e-01,  3.67507398e-01,\n",
       "         1.30230650e-01, -7.60662928e-03, -7.44654089e-02,\n",
       "        -2.22792834e-01, -4.08751294e-02,  1.74043268e-01,\n",
       "         7.88167492e-03,  8.40619057e-02,  3.21624845e-01,\n",
       "         5.63984960e-02,  5.03683761e-02, -1.75446197e-02,\n",
       "        -2.13296786e-01,  4.05042842e-02,  4.00367007e-03,\n",
       "        -2.64720857e-01,  3.80807906e-01, -7.55112171e+00,\n",
       "        -2.18862683e-01,  6.46360368e-02, -4.00215119e-01,\n",
       "        -2.77572051e-02, -1.25513464e-01,  2.87726521e-01,\n",
       "        -1.87558427e-01,  1.30613759e-01, -2.87674367e-01,\n",
       "         2.30826840e-01,  2.40418017e-02,  2.00412050e-03,\n",
       "        -6.43425211e-02,  3.30922991e-01,  3.64211202e-01]], dtype=float32)>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0][:,0,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Decode the original sentence from the tokenizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] didnt feel humiliated [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbert_tokenizer.decode(dbert_inp['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available labels:  ['sadness' 'fear' 'anger' 'love' 'happy' 'surprise']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>gt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16084</th>\n",
       "      <td>came home waiting shower read something made u...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8328</th>\n",
       "      <td>mostly feeling contentedly terrified</td>\n",
       "      <td>fear</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13309</th>\n",
       "      <td>cant help feel someones going end pissed</td>\n",
       "      <td>anger</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>feeling low forgotten</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7336</th>\n",
       "      <td>like always wanted feel accepted family others</td>\n",
       "      <td>love</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text    label  gt\n",
       "16084  came home waiting shower read something made u...  sadness   0\n",
       "8328                mostly feeling contentedly terrified     fear   1\n",
       "13309           cant help feel someones going end pissed    anger   2\n",
       "933                                feeling low forgotten  sadness   0\n",
       "7336      like always wanted feel accepted family others     love   3"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Available labels: \",data.label.unique())\n",
    "num_classes = len(data.label.unique())\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  6. Create a basic NN model using DistilBERT embeddings to get the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    inps = Input(shape = (max_len,), dtype='int64')\n",
    "    masks= Input(shape = (max_len,), dtype='int64')\n",
    "    dbert_layer = dbert_model(inps, attention_mask=masks)[0][:,0,:]\n",
    "    dense = Dense(512,activation='relu',kernel_regularizer=regularizers.l2(0.01))(dbert_layer)\n",
    "    dropout= Dropout(0.5)(dense)\n",
    "    pred = Dense(num_classes, activation='softmax',kernel_regularizer=regularizers.l2(0.01))(dropout)\n",
    "    model = tf.keras.Model(inputs=[inps,masks], outputs=pred)\n",
    "    print(model.summary())\n",
    "    return model   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Feel free to add more Dense and Dropout layers with variable units and the regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)        [(None, 32)]                 0         []                            \n",
      "                                                                                                  \n",
      " input_6 (InputLayer)        [(None, 32)]                 0         []                            \n",
      "                                                                                                  \n",
      " tf_distil_bert_model_5 (TF  TFBaseModelOutput(last_hid   6636288   ['input_5[0][0]',             \n",
      " DistilBertModel)            den_state=(None, 32, 768),   0          'input_6[0][0]']             \n",
      "                              hidden_states=None, atten                                           \n",
      "                             tions=None)                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_2  (None, 768)                  0         ['tf_distil_bert_model_5[0][0]\n",
      "  (SlicingOpLambda)                                                 ']                            \n",
      "                                                                                                  \n",
      " dense_4 (Dense)             (None, 512)                  393728    ['tf.__operators__.getitem_2[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " dropout_116 (Dropout)       (None, 512)                  0         ['dense_4[0][0]']             \n",
      "                                                                                                  \n",
      " dense_5 (Dense)             (None, 6)                    3078      ['dropout_116[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 66759686 (254.67 MB)\n",
      "Trainable params: 66759686 (254.67 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model=create_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Prepare the model input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fotiem.constant/.pyenv/versions/3.10.6/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2285: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "input_ids=[]\n",
    "attention_masks=[]\n",
    "\n",
    "for sent in sentences:\n",
    "    dbert_inps=dbert_tokenizer.encode_plus(sent,add_special_tokens = True,max_length =max_len,pad_to_max_length = True,return_attention_mask = True,truncation=True)\n",
    "    input_ids.append(dbert_inps['input_ids'])\n",
    "    attention_masks.append(dbert_inps['attention_mask'])\n",
    "\n",
    "input_ids=np.asarray(input_ids)\n",
    "attention_masks=np.array(attention_masks)\n",
    "labels=np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21459, 21459, 21459)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_ids),len(attention_masks),len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Save the model input in the pickle files to use it later without performing the above steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing the pickle file.....\n"
     ]
    }
   ],
   "source": [
    "print('Preparing the pickle file.....')\n",
    "\n",
    "pickle_inp_path='./data/pickle_files/dbert_inp.pkl'\n",
    "pickle_mask_path='./data/pickle_files/dbert_mask.pkl'\n",
    "pickle_label_path='./data/pickle_files/dbert_label.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickle files saved as  ./data/pickle_files/dbert_inp.pkl ./data/pickle_files/dbert_mask.pkl ./data/pickle_files/dbert_label.pkl\n"
     ]
    }
   ],
   "source": [
    "pickle.dump((input_ids),open(pickle_inp_path,'wb'))\n",
    "pickle.dump((attention_masks),open(pickle_mask_path,'wb'))\n",
    "pickle.dump((labels),open(pickle_label_path,'wb'))\n",
    "\n",
    "\n",
    "print('Pickle files saved as ',pickle_inp_path,pickle_mask_path,pickle_label_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the saved pickle files..\n",
      "Input shape (21459, 32) Attention mask shape (21459, 32) Input label shape (21459,)\n"
     ]
    }
   ],
   "source": [
    "print('Loading the saved pickle files..')\n",
    "\n",
    "input_ids=pickle.load(open(pickle_inp_path, 'rb'))\n",
    "attention_masks=pickle.load(open(pickle_mask_path, 'rb'))\n",
    "labels=pickle.load(open(pickle_label_path, 'rb'))\n",
    "\n",
    "print('Input shape {} Attention mask shape {} Input label shape {}'.format(input_ids.shape,attention_masks.shape,labels.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values(['sadness', 'fear', 'anger', 'love', 'happy', 'surprise'])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_class_dict = dict(enumerate(data['label'].unique()))\n",
    "target_names = label_class_dict.values()\n",
    "target_names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Train Test split and setting up the loss function, accuracy and optimizer for the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train inp shape (17167, 32) Val input shape (4292, 32)\n",
      "Train label shape (17167,) Val label shape (4292,)\n",
      "Train attention mask shape (17167, 32) Val attention mask shape (4292, 32)\n"
     ]
    }
   ],
   "source": [
    "train_inp,val_inp,train_label,val_label,train_mask,val_mask=train_test_split(input_ids,labels,attention_masks,test_size=0.2)\n",
    "\n",
    "print('Train inp shape {} Val input shape {}\\nTrain label shape {} Val label shape {}\\nTrain attention mask shape {} Val attention mask shape {}'.format(train_inp.shape,val_inp.shape,train_label.shape,val_label.shape,train_mask.shape,val_mask.shape))\n",
    "\n",
    "\n",
    "log_dir='dbert_model'\n",
    "model_save_path='./dbert_model.h5'\n",
    "\n",
    "callbacks = [tf.keras.callbacks.ModelCheckpoint(filepath=model_save_path,save_weights_only=True,monitor='val_loss',mode='min',save_best_only=True),keras.callbacks.TensorBoard(log_dir=log_dir)]\n",
    "\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5)\n",
    "\n",
    "model.compile(loss=loss,optimizer=optimizer, metrics=[metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks= [tf.keras.callbacks.ModelCheckpoint(filepath=model_save_path,save_weights_only=True,monitor='val_loss',mode='min',save_best_only=True),keras.callbacks.TensorBoard(log_dir=log_dir)]\n",
    "model.compile(loss=loss,optimizer=optimizer, metrics=[metric])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fotiem.constant/.pyenv/versions/3.10.6/lib/python3.10/site-packages/keras/src/backend.py:5727: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1073/1073 [==============================] - 5748s 5s/step - loss: 5.4224 - accuracy: 0.8374 - val_loss: 4.0729 - val_accuracy: 0.9271\n"
     ]
    }
   ],
   "source": [
    "history=model.fit([train_inp,train_mask],train_label,batch_size=16,epochs=1,validation_data=([val_inp,val_mask],val_label),callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboard visualization (Training-Testing curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-5d175bafbb146931\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-5d175bafbb146931\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir {log_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will Increase the number of epochs in order to decrease the loss further\n",
    "Here we will use the saved model for predictions and calculating the evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_7 (InputLayer)        [(None, 32)]                 0         []                            \n",
      "                                                                                                  \n",
      " input_8 (InputLayer)        [(None, 32)]                 0         []                            \n",
      "                                                                                                  \n",
      " tf_distil_bert_model_5 (TF  TFBaseModelOutput(last_hid   6636288   ['input_7[0][0]',             \n",
      " DistilBertModel)            den_state=(None, 32, 768),   0          'input_8[0][0]']             \n",
      "                              hidden_states=None, atten                                           \n",
      "                             tions=None)                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_3  (None, 768)                  0         ['tf_distil_bert_model_5[1][0]\n",
      "  (SlicingOpLambda)                                                 ']                            \n",
      "                                                                                                  \n",
      " dense_6 (Dense)             (None, 512)                  393728    ['tf.__operators__.getitem_3[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " dropout_117 (Dropout)       (None, 512)                  0         ['dense_6[0][0]']             \n",
      "                                                                                                  \n",
      " dense_7 (Dense)             (None, 6)                    3078      ['dropout_117[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 66759686 (254.67 MB)\n",
      "Trainable params: 66759686 (254.67 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "trained_model = create_model()\n",
    "trained_model.compile(loss=loss,optimizer=optimizer, metrics=[metric])\n",
    "trained_model.load_weights(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269/269 [==============================] - 248s 905ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9264214263864357"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = trained_model.predict([val_inp,val_mask],batch_size=16)\n",
    "pred_labels = preds.argmax(axis=1)\n",
    "f1 = f1_score(val_label, pred_labels, average='weighted')\n",
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_values(['sadness', 'fear', 'anger', 'love', 'happy', 'surprise'])\n",
      "(4292,)\n",
      "(4292,)\n",
      "F1 score: 0.9264214263864357\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.96      1228\n",
      "           1       0.83      0.91      0.87       492\n",
      "           2       0.94      0.91      0.92       627\n",
      "           3       0.85      0.87      0.86       328\n",
      "           4       0.96      0.95      0.95      1423\n",
      "           5       0.99      0.66      0.80       194\n",
      "\n",
      "    accuracy                           0.93      4292\n",
      "   macro avg       0.92      0.88      0.89      4292\n",
      "weighted avg       0.93      0.93      0.93      4292\n",
      "\n",
      "Training and saving built model...\n"
     ]
    }
   ],
   "source": [
    "print(target_names)\n",
    "# print(target_names.shape)\n",
    "print(val_label.shape)\n",
    "print(pred_labels.shape)\n",
    "\n",
    "\n",
    "# we print F1 score and classification report\n",
    "print('F1 score:', f1)\n",
    "print('Classification Report:')\n",
    "print(classification_report(val_label, pred_labels))\n",
    "\n",
    "print('Training and saving built model...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick test in real world scenario\n",
    "We are now gonna try to predict a sentence with any input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we try to predict the label of a random sentence from user\n",
    "def predict(sentence):\n",
    "    # we first preprocess the sentence\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "    # then we do some tokenization on the sentence\n",
    "    dbert_inps=dbert_tokenizer.encode_plus(sentence,add_special_tokens = True,max_length =max_len,pad_to_max_length = True,return_attention_mask = True,truncation=True)\n",
    "    # then we convert to numpy array\n",
    "    id_inp=np.asarray(dbert_inps['input_ids'])\n",
    "    mask_inp=np.asarray(dbert_inps['attention_mask'])\n",
    "    # and predict the label using the trained model\n",
    "    pred = trained_model.predict([id_inp.reshape(1,-1),mask_inp.reshape(1,-1)])\n",
    "    # and then get the label with the highest probability\n",
    "    pred_label = np.argmax(pred,axis=1)\n",
    "    # we then return it\n",
    "    return label_class_dict[pred_label[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fotiem.constant/.pyenv/versions/3.10.6/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2285: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'sadness'"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test the model on a random sentence\n",
    "predict(\"I was alone at home and now i have no idea what i will be doing for the next 2 weeks\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
